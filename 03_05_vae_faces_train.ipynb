{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "03_05_vae_faces_train.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iO-4AG-JrrE"
      },
      "source": [
        "# VAE Training - Faces dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdJu_w0kKW__",
        "outputId": "617473fc-53fc-4cf5-cdab-e4802e5c5085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/steffenmodest/GDL_code-tensorflow_2.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'GDL_code-tensorflow_2'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (80/80), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 80 (delta 30), reused 63 (delta 23), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (80/80), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A1YvzQSJrrG"
      },
      "source": [
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td2touwhJrrH"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjYUcWjQKceV"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/GDL_code-tensorflow_2')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1W6XffVJrrI"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "\n",
        "from models.VAE import VariationalAutoencoder\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usJft9BhJrrJ"
      },
      "source": [
        "# run params\n",
        "section = 'vae'\n",
        "run_id = '0001'\n",
        "data_name = 'faces'\n",
        "# RUN_FOLDER = 'run/{}/'.format(section)\n",
        "RUN_FOLDER = '/content/GDL_code-tensorflow_2/run/{}/'.format(section)\n",
        "RUN_FOLDER += '_'.join([run_id, data_name])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "mode =  'build' #'load' #\n",
        "\n",
        "\n",
        "DATA_FOLDER = './data/celeb/'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVW5vqAhJrrJ"
      },
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lHkhFxJJrrK"
      },
      "source": [
        "INPUT_DIM = (128,128,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
        "\n",
        "NUM_IMAGES = len(filenames)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1oYfZ-rJrrK",
        "outputId": "5a2e7e0e-ea8f-4a8e-d7c9-dbff6613ccda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "data_flow = data_gen.flow_from_directory(DATA_FOLDER\n",
        "                                         , target_size = INPUT_DIM[:2]\n",
        "                                         , batch_size = BATCH_SIZE\n",
        "                                         , shuffle = True\n",
        "                                         , class_mode = 'input'\n",
        "                                         , subset = \"training\"\n",
        "                                            )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-158905ec1a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          \u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                          \u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/celeb/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quFIWO0kJrrL"
      },
      "source": [
        "## architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgTzTw9JrrM"
      },
      "source": [
        "vae = VariationalAutoencoder(\n",
        "                input_dim = INPUT_DIM\n",
        "                , encoder_conv_filters=[32,64,64, 64]\n",
        "                , encoder_conv_kernel_size=[3,3,3,3]\n",
        "                , encoder_conv_strides=[2,2,2,2]\n",
        "                , decoder_conv_t_filters=[64,64,32,3]\n",
        "                , decoder_conv_t_kernel_size=[3,3,3,3]\n",
        "                , decoder_conv_t_strides=[2,2,2,2]\n",
        "                , z_dim=200\n",
        "                , use_batch_norm=True\n",
        "                , use_dropout=True\n",
        "                , r_loss_factor = 10000\n",
        "                )\n",
        "\n",
        "if mode == 'build':\n",
        "    vae.save(RUN_FOLDER)\n",
        "else:\n",
        "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf0Zz6KDJrrN"
      },
      "source": [
        "vae.encoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSfv_7KLJrrN"
      },
      "source": [
        "vae.decoder.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb4AxkDAJrrN"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2WOVDszJrrO"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 200\n",
        "PRINT_EVERY_N_BATCHES = 100\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3194qx0JrrO"
      },
      "source": [
        "vae.compile(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF-0aoXlJrrO"
      },
      "source": [
        "vae.train_with_generator(     \n",
        "    data_flow\n",
        "    , epochs = EPOCHS\n",
        "    , steps_per_epoch = NUM_IMAGES / BATCH_SIZE\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}